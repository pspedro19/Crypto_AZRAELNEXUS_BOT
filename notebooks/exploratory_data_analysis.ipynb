{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analsisi Exploratorio de Datos FACSAT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la ejecucion del siguiente proceso de exploracion y analisis de datos, se usaron las siguientes librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from pymongo import MongoClient\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y adicionalmente nos apoyamos en las siguientes funciones para llevar a cabo este proceso de forma automatica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de estilo para gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Función para cargar datos desde MongoDB\n",
    "def load_data(mongo_uri: str, db_name: str, collection: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta en MongoDB con parámetros de conexión separados y opciones de consulta flexibles.\n",
    "    \n",
    "    Args:\n",
    "        mongo_uri (str): URI de conexión a MongoDB (incluyendo credenciales si es necesario)\n",
    "        db_name (str): Nombre de la base de datos\n",
    "        collection (str): Nombre de la colección\n",
    "        **kwargs: Argumentos opcionales para la consulta\n",
    "            - query (dict): Filtro de la consulta (default: {})\n",
    "            - projection (dict): Campos a proyectar (default: {})\n",
    "            - skip (int): Número de documentos a saltar (default: 0)\n",
    "            - limit (int): Límite de documentos a retornar (default: 0)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame con los datos de la consulta\n",
    "    \n",
    "    Raises:\n",
    "        Exception: Si hay errores en la conexión o consulta\n",
    "    \"\"\"\n",
    "    query = kwargs.get('query', {})\n",
    "    projection = kwargs.get('projection', {})\n",
    "    skip = kwargs.get('skip', 0)\n",
    "    limit = kwargs.get('limit', 0)\n",
    "    \n",
    "    try:\n",
    "        client = MongoClient(mongo_uri)\n",
    "        db = client[db_name]\n",
    "        collection_obj = db[collection]\n",
    "\n",
    "        result = collection_obj.find(\n",
    "            query,\n",
    "            projection\n",
    "        ).skip(skip).limit(limit)\n",
    "        \n",
    "        return pd.json_normalize(list(result))\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error al ejecutar la consulta MongoDB: {str(e)}\")\n",
    "\n",
    "# Generar ambos gráficos en una sola figura\n",
    "def plot_histogram_and_boxplot(data, col, sistema, tabla):\n",
    "    # display(Markdown(f\"- Graficos de la variable {col.split(f'{sistema+tabla}_')[1]}:\"))\n",
    "    \n",
    "    # Crear una figura con dos subplots, uno al lado del otro\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    # Histograma\n",
    "    sns.histplot(data[col].dropna(), kde=True, bins=15, ax=axes[0])\n",
    "    axes[0].set_title(f\"Histograma - {col.split(f'{sistema+tabla}_')[1]} ({sistema} tabla {tabla})\")\n",
    "    axes[0].set_xlabel(col.split(f'{sistema+tabla}_')[1])\n",
    "\n",
    "    sns.boxplot(x=data[col].dropna(), ax=axes[1])\n",
    "    axes[1].set_title(f\"Boxplot - {col.split(f'{sistema+tabla}_')[1]} ({sistema} tabla {tabla})\")\n",
    "    axes[1].set_xlabel(col.split(f'{sistema+tabla}_')[1])\n",
    "    \n",
    "    # Ajustar los espacios entre los subplots\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Mostrar la figura\n",
    "    plt.show()\n",
    "\n",
    "def crear_tabla_estadisticas(df_desc):\n",
    "    \"\"\"\n",
    "    Crea y muestra una tabla de estadísticas descriptivas con formato mejorado.\n",
    "    \n",
    "    Args:\n",
    "        df_desc: DataFrame con las estadísticas descriptivas\n",
    "    \"\"\"\n",
    "    # Formatear valores numéricos para mejor legibilidad\n",
    "    df_formatted = df_desc.copy()\n",
    "    for columna in df_formatted.columns:\n",
    "        if columna not in ['count', 'null_count']:\n",
    "            df_formatted[columna] = df_formatted[columna].apply(lambda x: f\"{x:.2f}\")\n",
    "        else:\n",
    "            df_formatted[columna] = df_formatted[columna].apply(lambda x: f\"{int(x)}\")\n",
    "    \n",
    "    # Crear figura y tabla\n",
    "    fig, ax = plt.subplots(figsize=(14, 1.5))\n",
    "    \n",
    "    # Crear tabla con mejores ajustes\n",
    "    tabla = ax.table(\n",
    "        cellText=df_formatted.values,\n",
    "        colLabels=df_formatted.columns,\n",
    "        loc='center',\n",
    "        cellLoc='center',\n",
    "        colWidths=[0.11] * len(df_formatted.columns)\n",
    "    )\n",
    "    \n",
    "    # Ajustar estilo de la tabla\n",
    "    tabla.auto_set_font_size(False)\n",
    "    tabla.set_fontsize(12)\n",
    "    tabla.scale(1, 1.8)  # Aumentar altura de las celdas\n",
    "    \n",
    "    # Estilizar celdas\n",
    "    for k, cell in tabla._cells.items():\n",
    "        cell.set_edgecolor('black')\n",
    "        if k[0] == 0:  # Encabezados\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor('#e6e6e6')\n",
    "            cell.set_fontsize(14)\n",
    "    \n",
    "    # Ajustes finales de la figura\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Análisis univariado para cada sistema y tabla\n",
    "def univariate_analysis(data, system_name):\n",
    "    # Configuración general de matplotlib\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "        plt.style.use('seaborn')\n",
    "    except:\n",
    "        # Si seaborn no está disponible, usar estilo básico de matplotlib\n",
    "        plt.style.use('default')\n",
    "\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['figure.facecolor'] = 'white'\n",
    "    # plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "    # Extraer nombre del sistema y tabla\n",
    "    sistema = str(system_name.split(\"_\")[0])\n",
    "    tabla = str(system_name.split(\"_\")[1])\n",
    "\n",
    "    # Mostrar título del sistema\n",
    "    display(Markdown(f\"### Sistema {system_name}:\"))\n",
    "    \n",
    "    # Distribución de variables numéricas\n",
    "    for col in data.select_dtypes(include=[np.number]).columns:\n",
    "        display(Markdown(f\"### Análisis de la variable `{col.split(f'{sistema+tabla}_')[1]}`\"))\n",
    "        display(Markdown(f\"#### Estadisticas descriptivas:\"))\n",
    "        # Estadísticas descriptivas\n",
    "        df_desc = pd.DataFrame(data[col].describe())\n",
    "        df_desc.loc['null_count'] = data[col].isnull().sum()\n",
    "        df_desc = df_desc.T\n",
    "\n",
    "        # Crear y mostrar la tabla\n",
    "        crear_tabla_estadisticas(df_desc)\n",
    "\n",
    "        # Crear una figura con dos subplots\n",
    "        display(Markdown(f\"#### Graficos descriptivos:\"))\n",
    "        plot_histogram_and_boxplot(data, col, sistema, tabla)\n",
    "\n",
    "# Análisis multivariado entre variables de diferentes sistemas\n",
    "def multivariate_analysis(merged_df):\n",
    "    print(f\"\\n--- Análisis multivariado (sistemas combinados) ---\")\n",
    "    \n",
    "    # Matriz de correlación\n",
    "    corr_matrix = merged_df.corr()\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "    plt.title(\"Matriz de correlación entre variables de diferentes sistemas\")\n",
    "    plt.show()\n",
    "    \n",
    "    # PCA para reducir la dimensionalidad y visualizar patrones\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(merged_df.dropna())\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_data = pca.fit_transform(scaled_data)\n",
    "    \n",
    "    plt.scatter(pca_data[:, 0], pca_data[:, 1], alpha=0.5)\n",
    "    plt.title(\"PCA - Componentes principales de los datos combinados de sistemas\")\n",
    "    plt.xlabel(\"Componente Principal 1\")\n",
    "    plt.ylabel(\"Componente Principal 2\")\n",
    "    plt.show()\n",
    "    \n",
    "    return corr_matrix, pca_data\n",
    "\n",
    "# Detección de anomalías con Z-score\n",
    "def zscore_anomaly_detection(merged_df, threshold=3):\n",
    "    z_scores = np.abs(zscore(merged_df.dropna()))\n",
    "    anomalies = (z_scores > threshold).any(axis=1)\n",
    "    \n",
    "    print(f\"Anomalías detectadas: {np.sum(anomalies)}\")\n",
    "    \n",
    "    return merged_df[anomalies], anomalies\n",
    "\n",
    "# Función principal para ejecutar el análisis completo\n",
    "def main():\n",
    "\n",
    "    # Configuración de conexión a MongoDB\n",
    "    mongo_uri = \"mongodb://localhost:27017/\"\n",
    "    db_name = \"etl_data\"\n",
    "    \n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "\n",
    "    collections = db.list_collection_names()  # Lista de colecciones por sistema\n",
    "    \n",
    "    # Cargar datos de cada sistema\n",
    "    data_frames = []\n",
    "    for collection in collections:\n",
    "        # Cargar datos\n",
    "        data = load_data(mongo_uri=mongo_uri, db_name=db_name, collection=collection)\n",
    "        data_frames.append(data)\n",
    "        \n",
    "        # # Análisis Univariado\n",
    "        # # Insertar un título de Markdown\n",
    "        # display(Markdown(\"## Análisis Univariado\"))\n",
    "        # univariate_analysis(data, collection)\n",
    "        \n",
    "    # Fusión de datos para el análisis multivariado y la detección de anomalías\n",
    "    merged_df = pd.concat(data_frames, axis=1, join=\"inner\")\n",
    "\n",
    "    # Insertar un subtítulo para el siguiente análisis\n",
    "    display(Markdown(\"## Análisis Multivariado\"))\n",
    "    corr_matrix, pca_data = multivariate_analysis(merged_df)\n",
    "    \n",
    "    # Detección de anomalías\n",
    "    anomalies, anomaly_flags = zscore_anomaly_detection(merged_df)\n",
    "\n",
    "    return {\n",
    "        \"correlation_matrix\": corr_matrix,\n",
    "        \"pca_data\": pca_data,\n",
    "        \"anomalies\": anomalies,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para llevar a cabo la ejecucion del proceso automatico, se debe ejecutar la siguiente funcion principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Análisis Multivariado"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Análisis multivariado (sistemas combinados) ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'ObjectId'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Llamada principal\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     eda_results \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 212\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Insertar un subtítulo para el siguiente análisis\u001b[39;00m\n\u001b[1;32m    211\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Análisis Multivariado\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 212\u001b[0m corr_matrix, pca_data \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# Detección de anomalías\u001b[39;00m\n\u001b[1;32m    215\u001b[0m anomalies, anomaly_flags \u001b[38;5;241m=\u001b[39m zscore_anomaly_detection(merged_df)\n",
      "Cell \u001b[0;32mIn[2], line 155\u001b[0m, in \u001b[0;36mmultivariate_analysis\u001b[0;34m(merged_df)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Análisis multivariado (sistemas combinados) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Matriz de correlación\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(corr_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m\"\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de correlación entre variables de diferentes sistemas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documentos/FACSAT-2/Git_Repo/DataMiningFACSAT2/.venv/lib/python3.10/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/Documentos/FACSAT-2/Git_Repo/DataMiningFACSAT2/.venv/lib/python3.10/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documentos/FACSAT-2/Git_Repo/DataMiningFACSAT2/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/Documentos/FACSAT-2/Git_Repo/DataMiningFACSAT2/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'ObjectId'"
     ]
    }
   ],
   "source": [
    "# Llamada principal\n",
    "if __name__ == \"__main__\":\n",
    "    eda_results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
